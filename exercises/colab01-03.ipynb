{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"382.391px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"Copy of exercise01-Introduction.ipynb","provenance":[{"file_id":"https://github.com/ray-project/tutorial/blob/master/exercises/exercise01-Introduction.ipynb","timestamp":1569885863522}],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"l6wpgwlHdfus","colab_type":"text"},"source":["# Exercise 1 - Simple Data Parallel Example\n","\n","**GOAL:** The goal of this exercise is to show how to run simple tasks in parallel.\n","\n","This script is too slow, and the computation is embarrassingly parallel. In this exercise, you will use Ray to execute the functions in parallel to speed it up.\n","\n","### Concept for this Exercise - Remote Functions\n","\n","The standard way to turn a Python function into a remote function is to add the `@ray.remote` decorator. Here is an example.\n","\n","```python\n","# A regular Python function.\n","def regular_function():\n","    return 1\n","\n","# A Ray remote function.\n","@ray.remote\n","def remote_function():\n","    return 1\n","```\n","\n","The differences are the following:\n","\n","1. **Invocation:** The regular version is called with `regular_function()`, whereas the remote version is called with `remote_function.remote()`.\n","2. **Return values:** `regular_function` immediately executes and returns `1`, whereas `remote_function` immediately returns an object ID (a future) and then creates a task that will be executed on a worker process. The result can be obtained with `ray.get`.\n","    ```python\n","    >>> regular_function()\n","    1\n","    \n","    >>> remote_function.remote()\n","    ObjectID(1c80d6937802cd7786ad25e50caf2f023c95e350)\n","    \n","    >>> ray.get(remote_function.remote())\n","    1\n","    ```\n","3. **Parallelism:** Invocations of `regular_function` happen **serially**, for example\n","    ```python\n","    # These happen serially.\n","    for _ in range(4):\n","        regular_function()\n","    ```\n","    whereas invocations of `remote_function` happen in **parallel**, for example\n","    ```python\n","    # These happen in parallel.\n","    for _ in range(4):\n","        remote_function.remote()\n","    ```"]},{"cell_type":"code","metadata":{"id":"xLJx-XpJdfuu","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import ray\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PvwwpldHdfux","colab_type":"text"},"source":["Start Ray. By default, Ray does not schedule more tasks concurrently than there are CPUs. This example requires four tasks to run concurrently, so we tell Ray that there are four CPUs. Usually this is not done and Ray computes the number of CPUs using `psutil.cpu_count()`. The argument `ignore_reinit_error=True` just ignores errors if the cell is run multiple times.\n","\n","The call to `ray.init` starts a number of processes."]},{"cell_type":"code","metadata":{"id":"1MjLO5L4dfux","colab_type":"code","colab":{}},"source":["ray.init(num_cpus=4, ignore_reinit_error=True, include_webui=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tyu--hNTdfuz","colab_type":"text"},"source":["**EXERCISE:** The function below is slow. Turn it into a remote function using the `@ray.remote` decorator."]},{"cell_type":"code","metadata":{"id":"H5nmhkpbdfuz","colab_type":"code","colab":{}},"source":["# This function is a proxy for a more interesting and computationally\n","# intensive function.\n","def slow_function(i):\n","    time.sleep(1)\n","    return i"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D35JdJQ8dfu1","colab_type":"text"},"source":["**EXERCISE:** The loop below takes too long. The four function calls could be executed in parallel. Instead of four seconds, it should only take one second. Once `slow_function` has been made a remote function, execute these four tasks in parallel by calling `slow_function.remote()`. Then obtain the results by calling `ray.get` on a list of the resulting object IDs."]},{"cell_type":"code","metadata":{"id":"pnNgl3cddfu2","colab_type":"code","colab":{}},"source":["# Sleep a little to improve the accuracy of the timing measurements below.\n","# We do this because workers may still be starting up in the background.\n","time.sleep(2.0)\n","start_time = time.time()\n","\n","results = [slow_function(i) for i in range(4)]\n","\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","print('The results are {}. This took {} seconds. Run the next cell to see '\n","      'if the exercise was done correctly.'.format(results, duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r_FfKxocdfu3","colab_type":"text"},"source":["**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."]},{"cell_type":"code","metadata":{"id":"IlrIrAyldfu4","colab_type":"code","colab":{}},"source":["assert results == [0, 1, 2, 3], 'Did you remember to call ray.get?'\n","assert duration < 1.1, ('The loop took {} seconds. This is too slow.'\n","                        .format(duration))\n","assert duration > 1, ('The loop took {} seconds. This is too fast.'\n","                      .format(duration))\n","\n","print('Success! The example took {} seconds.'.format(duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AC1rwahidfu5","colab_type":"text"},"source":["**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n","\n","1. Run the following cell to generate a JSON file containing the profiling data.\n","2. Download the timeline file by right clicking on `timeline01.json` in the navigator to the left and choosing **\"Download\"**.\n","3. Open [chrome://tracing/](chrome://tracing/) in the Chrome web browser, click on the **\"Load\"** button and load the downloaded JSON file.\n","\n","To navigate within the timeline, do the following.\n","- Move around by clicking and dragging.\n","- Zoom in and out by holding **alt** and scrolling.\n","\n","**NOTE:** The timeline visualization will only work in **Chrome**."]},{"cell_type":"code","metadata":{"id":"LmYOA4sGdfu6","colab_type":"code","colab":{}},"source":["ray.timeline(filename=\"timeline01.json\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TD9T8jPYd2bO","colab_type":"text"},"source":["# Exercise 2 - Parallel Data Processing with Task Dependencies\n","\n","**GOAL:** The goal of this exercise is to show how to pass object IDs into remote functions to encode dependencies between tasks.\n","\n","In this exercise, we construct a sequence of tasks each of which depends on the previous mimicking a data parallel application. Within each sequence, tasks are executed serially, but multiple sequences can be executed in parallel.\n","\n","In this exercise, you will use Ray to parallelize the computation below and speed it up.\n","\n","### Concept for this Exercise - Task Dependencies\n","\n","Suppose we have two remote functions defined as follows.\n","\n","```python\n","@ray.remote\n","def f(x):\n","    return x\n","```\n","\n","Arguments can be passed into remote functions as usual.\n","\n","```python\n",">>> x1_id = f.remote(1)\n",">>> ray.get(x1_id)\n","1\n","\n",">>> x2_id = f.remote([1, 2, 3])\n",">>> ray.get(x2_id)\n","[1, 2, 3]\n","```\n","\n","**Object IDs** can also be passed into remote functions. When the function actually gets executed, **the argument will be a retrieved as a regular Python object**.\n","\n","```python\n",">>> y1_id = f.remote(x1_id)\n",">>> ray.get(y1_id)\n","1\n","\n",">>> y2_id = f.remote(x2_id)\n",">>> ray.get(y2_id)\n","[1, 2, 3]\n","```\n","\n","So when implementing a remote function, the function should expect a regular Python object regardless of whether the caller passes in a regular Python object or an object ID.\n","\n","**Task dependencies affect scheduling.** In the example above, the task that creates `y1_id` depends on the task that creates `x1_id`. This has the following implications.\n","\n","- The second task will not be executed until the first task has finished executing.\n","- If the two tasks are scheduled on different machines, the output of the first task (the value corresponding to `x1_id`) will be copied over the network to the machine where the second task is scheduled."]},{"cell_type":"code","metadata":{"id":"jRayjahDd-AU","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import ray\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csUGAU13d-Zs","colab_type":"code","colab":{}},"source":["ray.init(num_cpus=4, include_webui=False, ignore_reinit_error=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dGrF31cceDMk","colab_type":"text"},"source":["These are some helper functions that mimic an example pattern of a data parallel application.\n","\n","**EXERCISE:** You will need to turn all of these functions into remote functions. When you turn these functions into remote function, you do not have to worry about whether the caller passes in an object ID or a regular object. In both cases, the arguments will be regular objects when the function executes. This means that even if you pass in an object ID, you **do not need to call `ray.get`** inside of these remote functions."]},{"cell_type":"code","metadata":{"id":"ZU1nRG8beACP","colab_type":"code","colab":{}},"source":["def load_data(filename):\n","    time.sleep(0.1)\n","    return np.ones((1000, 100))\n","\n","def normalize_data(data):\n","    time.sleep(0.1)\n","    return data - np.mean(data, axis=0)\n","\n","def extract_features(normalized_data):\n","    time.sleep(0.1)\n","    return np.hstack([normalized_data, normalized_data ** 2])\n","\n","def compute_loss(features):\n","    num_data, dim = features.shape\n","    time.sleep(0.1)\n","    return np.sum((np.dot(features, np.ones(dim)) - np.ones(num_data)) ** 2)\n","\n","assert hasattr(load_data, 'remote'), 'load_data must be a remote function'\n","assert hasattr(normalize_data, 'remote'), 'normalize_data must be a remote function'\n","assert hasattr(extract_features, 'remote'), 'extract_features must be a remote function'\n","assert hasattr(compute_loss, 'remote'), 'compute_loss must be a remote function'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlF-_kc2eHc4","colab_type":"text"},"source":["**EXERCISE:** The loop below takes too long. Parallelize the four passes through the loop by turning `load_data`, `normalize_data`, `extract_features`, and `compute_loss` into remote functions and then retrieving the losses with `ray.get`.\n","\n","**NOTE:** You should only use **ONE** call to `ray.get`. For example, the object ID returned by `load_data` should be passed directly into `normalize_data` without needing to be retrieved by the driver."]},{"cell_type":"code","metadata":{"id":"rX-brDlaeFNZ","colab_type":"code","colab":{}},"source":["# Sleep a little to improve the accuracy of the timing measurements below.\n","time.sleep(2.0)\n","start_time = time.time()\n","\n","losses = []\n","for filename in ['file1', 'file2', 'file3', 'file4']:\n","    inner_start = time.time()\n","\n","    data = load_data(filename)\n","    normalized_data = normalize_data(data)\n","    features = extract_features(normalized_data)\n","    loss = compute_loss(features)\n","    losses.append(loss)\n","    \n","    inner_end = time.time()\n","    \n","    if inner_end - inner_start >= 0.1:\n","        raise Exception('You may be calling ray.get inside of the for loop! '\n","                        'Doing this will prevent parallelism from being exposed. '\n","                        'Make sure to only call ray.get once outside of the for loop.')\n","\n","print('The losses are {}.'.format(losses) + '\\n')\n","loss = sum(losses)\n","\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","print('The loss is {}. This took {} seconds. Run the next cell to see '\n","      'if the exercise was done correctly.'.format(loss, duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOevdR4LeLlk","colab_type":"text"},"source":["**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."]},{"cell_type":"code","metadata":{"id":"FlTAyw09eJSL","colab_type":"code","colab":{}},"source":["assert loss == 4000\n","assert duration < 0.8, ('The loop took {} seconds. This is too slow.'\n","                        .format(duration))\n","assert duration > 0.4, ('The loop took {} seconds. This is too fast.'\n","                        .format(duration))\n","\n","print('Success! The example took {} seconds.'.format(duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r1fHJZWDeRGb","colab_type":"text"},"source":["**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n","\n","1. Run the following cell to generate a JSON file containing the profiling data.\n","2. Download the timeline file by right clicking on `timeline02.json` in the navigator to the left and choosing **\"Download\"**.\n","3. Open [chrome://tracing/](chrome://tracing/) in the Chrome web browser, click on the **\"Load\"** button and load the downloaded JSON file.\n","\n","To navigate within the timeline, do the following.\n","- Move around by clicking and dragging.\n","- Zoom in and out by holding **alt** and scrolling.\n","\n","**NOTE:** The timeline visualization will only work in **Chrome**."]},{"cell_type":"code","metadata":{"id":"R96y_U99eRdg","colab_type":"code","colab":{}},"source":["ray.timeline(filename=\"timeline02.json\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4UMNWDWOeVI2","colab_type":"text"},"source":["### Application: Parallel web-scraping\n","\n","One useful application of what we have learned so far is to scrape information from the web. We will illustrate this in a toy setting, but the same principles apply on a large scale where crawling through websites, parsing them and extracting useful content (e.g. for building a search index or populating a database) is often very computationally demanding.\n","\n","We break up the process into multiple steps. We first grab the raw HTML of the website using Python's requests package. Then, we use BeautifulSoup to parse the HTML to find the relevant information. Finally, we populate a pandas DataFrames so that we are able to work with the data.\n","\n","To demonstrate this, we scrape GitHub commits to see the latest commits on several repositories."]},{"cell_type":"code","metadata":{"id":"6apTGnCZeTDA","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup\n","import requests\n","\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IYW3fS-Aeg2s","colab_type":"text"},"source":["The following function uses these libraries to parse the latest commits from several repositories on GitHub."]},{"cell_type":"code","metadata":{"id":"GXRdG9zYehhI","colab_type":"code","colab":{}},"source":["def fetch_commits(repo):\n","    url = 'https://github.com/{}/commits/master'.format(repo)\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.text, 'lxml')\n","    df = pd.DataFrame(columns=['title', 'link'])\n","    for g in soup.find_all(class_='commit-title'):\n","        entry = {}\n","        title = g.find_all(class_='message')[0]['aria-label']\n","        entry['title'] = title\n","        links = g.find_all(class_='issue-link')\n","        if len(links) >= 1:\n","            link = links[0]['data-url']\n","            entry['link'] = link\n","        df = df.append(pd.DataFrame(entry, index=[0]), sort=False)\n","    \n","    df['repository'] = repo\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjhbi8UXen7d","colab_type":"text"},"source":["Let's try this out to get results for some ray related topics serially."]},{"cell_type":"code","metadata":{"id":"XENYO57kepSU","colab_type":"code","colab":{}},"source":["start = time.time()\n","repos = [\"ray-project/ray\", \"modin-project/modin\", \"tensorflow/tensorflow\", \"apache/arrow\"]\n","results = []\n","for repo in repos:\n","    df = fetch_commits(repo)\n","    results.append(df)\n","    \n","df = pd.concat(results, sort=False)\n","duration = time.time() - start\n","print(\"Constructing the dataframe took {} seconds.\".format(duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eZ5VmqgoerPb","colab_type":"text"},"source":["**EXERCISE**: Speed up the above serial query by making `fetch_commits` a remote function in order to scrape GitHub results in parallel. Then, see a sample of the data scraped below and feel free to play with the data to find other resources to learn more about these libraries!"]},{"cell_type":"code","metadata":{"id":"58RIGdF1etXY","colab_type":"code","colab":{}},"source":["df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-c-u7Nvewci","colab_type":"text"},"source":["# Exercise 3 - Nested Parallelism\n","\n","**GOAL:** The goal of this exercise is to show how to create nested tasks by calling a remote function inside of another remote function.\n","\n","In this exercise, you will implement the structure of a parallel hyperparameter sweep which trains a number of models in parallel. Each model will be trained using parallel gradient computations.\n","\n","### Concepts for this Exercise - Nested Remote Functions\n","\n","Remote functions can call other functions. For example, consider the following.\n","\n","```python\n","@ray.remote\n","def f():\n","    return 1\n","\n","@ray.remote\n","def g():\n","    # Call f 4 times and return the resulting object IDs.\n","    return [f.remote() for _ in range(4)]\n","\n","@ray.remote\n","def h():\n","    # Call f 4 times, block until those 4 tasks finish,\n","    # retrieve the results, and return the values.\n","    return ray.get([f.remote() for _ in range(4)])\n","```\n","\n","Then calling `g` and `h` produces the following behavior.\n","\n","```python\n",">>> ray.get(g.remote())\n","[ObjectID(b1457ba0911ae84989aae86f89409e953dd9a80e),\n"," ObjectID(7c14a1d13a56d8dc01e800761a66f09201104275),\n"," ObjectID(99763728ffc1a2c0766a2000ebabded52514e9a6),\n"," ObjectID(9c2f372e1933b04b2936bb6f58161285829b9914)]\n","\n",">>> ray.get(h.remote())\n","[1, 1, 1, 1]\n","```\n","\n","**One limitation** is that the definition of `f` must come before the definitions of `g` and `h` because as soon as `g` is defined, it will be pickled and shipped to the workers, and so if `f` hasn't been defined yet, the definition will be incomplete."]},{"cell_type":"code","metadata":{"id":"ppUDwvBMe0ue","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import ray\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aEuUdJDe-uY","colab_type":"code","colab":{}},"source":["ray.init(num_cpus=9, include_webui=False, ignore_reinit_error=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKX1DnmbfAJv","colab_type":"text"},"source":["This example represents a hyperparameter sweep in which multiple models are trained in parallel. Each model training task also performs data parallel gradient computations.\n","\n","**EXERCISE:** Turn `compute_gradient` and `train_model` into remote functions so that they can be executed in parallel. Inside of `train_model`, do the calls to `compute_gradient` in parallel and fetch the results using `ray.get`."]},{"cell_type":"code","metadata":{"id":"GAdMoSp7fBxV","colab_type":"code","colab":{}},"source":["def compute_gradient(data, current_model):\n","    time.sleep(0.03)\n","    return 1\n","\n","def train_model(hyperparameters):\n","    current_model = 0\n","    # Iteratively improve the current model. This outer loop cannot be parallelized.\n","    for _ in range(10):\n","        # EXERCISE: Parallelize the list comprehension in the line below. After you\n","        # turn \"compute_gradient\" into a remote function, you will need to call it\n","        # with \".remote\". The results must be retrieved with \"ray.get\" before \"sum\"\n","        # is called.\n","        total_gradient = sum([compute_gradient(j, current_model) for j in range(2)])\n","        current_model += total_gradient\n","\n","    return current_model\n","\n","assert hasattr(compute_gradient, 'remote'), 'compute_gradient must be a remote function'\n","assert hasattr(train_model, 'remote'), 'train_model must be a remote function'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6yR2xgWhfEK3","colab_type":"text"},"source":["**EXERCISE:** The code below runs 3 hyperparameter experiments. Change this to run the experiments in parallel."]},{"cell_type":"code","metadata":{"id":"KQhgStdSfGMt","colab_type":"code","colab":{}},"source":["# Sleep a little to improve the accuracy of the timing measurements below.\n","time.sleep(2.0)\n","start_time = time.time()\n","\n","# Run some hyperparaameter experiments.\n","results = []\n","for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n","                        {'learning_rate': 1e-2, 'batch_size': 100},\n","                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n","    results.append(train_model(hyperparameters))\n","\n","# EXERCISE: Once you've turned \"results\" into a list of Ray ObjectIDs\n","# by calling train_model.remote, you will need to turn \"results\" back\n","# into a list of integers, e.g., by doing \"results = ray.get(results)\".\n","\n","end_time = time.time()\n","duration = end_time - start_time\n","\n","assert all([isinstance(x, int) for x in results]), \\\n","    'Looks like \"results\" is {}. You may have forgotten to call ray.get.'.format(results)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZbRvJ9JfJcl","colab_type":"text"},"source":["**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass.\n","\n","**NOTE:** This exercise is known to have issues on binder that can be resolved by rerunning the above cell a second time."]},{"cell_type":"code","metadata":{"id":"BN6QZZGEfLAu","colab_type":"code","colab":{}},"source":["assert results == [20, 20, 20]\n","assert duration < 0.5, ('The experiments ran in {} seconds. This is too '\n","                         'slow.'.format(duration))\n","assert duration > 0.3, ('The experiments ran in {} seconds. This is too '\n","                        'fast.'.format(duration))\n","\n","print('Success! The example took {} seconds.'.format(duration))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xuf2d5mrfMms","colab_type":"text"},"source":["**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n","\n","1. Run the following cell to generate a JSON file containing the profiling data.\n","2. Download the timeline file by right clicking on `timeline03.json` in the navigator to the left and choosing **\"Download\"**.\n","3. Open [chrome://tracing/](chrome://tracing/) in the Chrome web browser, click on the **\"Load\"** button and load the downloaded JSON file.\n","\n","To navigate within the timeline, do the following.\n","- Move around by clicking and dragging.\n","- Zoom in and out by holding **alt** and scrolling.\n","\n","**NOTE:** The timeline visualization will only work in **Chrome**."]},{"cell_type":"code","metadata":{"id":"7WoR39fnfOlx","colab_type":"code","colab":{}},"source":["ray.timeline(filename=\"timeline03.json\")"],"execution_count":0,"outputs":[]}]}